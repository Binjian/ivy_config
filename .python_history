import time
time.__file__
import os
os.__file__
import tensorflow as tf
tf.__file__
import tensorflow
tensorflow.__file__
import tensorflow as tf
tf.__file__
import tensorflow as tf
tf.__version__
import tensroflow as tf
import tensorflow as tf
tf.__file__
import tensorflow as tf
tf.__file__
import tensorflow as tf
sys_details = tf.sysconfi.get_build_info()
sys_details = tf.sysconfig.get_build_info()
cuda_version = sys_details["cuda_version"]
print(cuda_version)
cudnn_version = sys_details["cudnn_version"]
print(cudnn_version)
print(sys_details["cuda_path"])
print(sys_details["cudart_dll_name"])
print(sys_details["is_cuda_build"])
print(sys_details["nvcuda_dll_name"])
print(sys_details["cuda_version"])
print(sys_details["cudart_dll_name"])
print(sys_details)
print(tf.sysconfig.get_link_flags())
print(tf.sysconfig.get_lib())
print(tf.sysconfig.get_comile_flags())
print(tf.sysconfig.get_compile_flags())
print(tf.sysconfig.get_link_flags())
print(tf.sysconfig.get_build_info())
print(tf.sysconfig.get_compile_flags())
print(tf.sysconfig.get_include())
print(tf.sysconfig.get_lib())
print(tf.sysconfig.get_linkflags())
print(tf.sysconfig.get_link_flags())
import tensorflow as tf
import torch
torch.__file__
import pytest
pytest.__file__
sa = {'a', ''aa', 'aaa'}
sa = {'a', 'aa', 'aaa'}
type(sa)
sa[0]
walrus = False
walrus
(walrus:=False)
walrus
(walrus:=True)
walrus
(walrus:=False)
walrus
walrus:=False
import pandas as pd
pd?
import tensorflow as tf
tf.sysconfig.get_build_info()
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.__file__
tf.__version__
import tensorflow as tf
tf.__version__
tf.__file__
import pymongoarrow as pma
pma.__version__
pma.__file__
import os
os.getcwd()
os.chdir('07-1class-func')
os.getcwd()
from tagger.py import tag
from tagger import tag
tag('br')
divmod(10,4)
divmod(11,4)
divmod?
ipython
from epc.server import EPCServer
from chatgpt_wrapper import ChatGPT
from chatgpt_wrapper import ChatGPT\
from chatgpt_wrapper import ChatGPT
import dask
import dask.dataframe as dd
import pyodbc
import eos
eos.__file__
import dask
import pandas as pd
ddf = dask.datasets.timeseries()
ddf.head()
ddf
ddf.dtype
ddf.dtypes
def my_custom_arithmetic(r):
    if r.id > 1000:
        return r.x * r.x + r.y + r.y
    else:
        return 0
ddf.apply(
    my_custom_arithmetic, axis=1, meta=pd.Series(dtype="float64")
myc = ddf.apply(
    my_custom_arithmetic, axis=1, meta=pd.Series(dtype="float64")
myc = ddf.apply(my_custom_arithmetic, axis=1, meta=pd.Series(dtype="float64")) 
myc
myc.dtypes
myc.dtype
myc.head()
ddf.head()
ddf["my_compuation"]=myc
ddf.head()
 = ddf.apply(my_custom_arithmetic, axis=1) 
ddf.meta
ddf._meta
ddf.types
ddf.dtypes
ddf._meta
ddf.columns
ddf.index
myc.visualize()
import tensorflow as tf
tf.__file__
import tensorflow as tf
import pymongo as pg
import pymongo as pmg
pmg.__file__
quit
import cutelog
cutelog.__file__
cutelog.__version__
cutelog.version
import pkg_resources
pkg_resources.get_distribution("cutelog").version
import tensorflow as tf
import pandas as pd
pd.__version__
import OrderedSet
import ordered_set
from ordered_set import OrderedSet
ordered_set.__version__
ordered_set.__file__
import _typeshed
import typeshed
import os
os.getcwd()
os.chdir('05-data-classes')
os.getcwd()
os.chdir('dataclass')
os.getcwd()
from hackclub import HackerClubMember 
from hackerclub import HackerClubMember 
leo = HackerClubMember('Leo Rochael')
leo = HackerClubMember('Leo DaVinci')
HackerClubMember.__doc__
HackerClubMember.__dict__
HackerClubMember.__repr__
HackerClubMember.__str__
HackerClubMember.__doc__
HackerClubMember.__class__
quit()
1024*16
1024*32
import torch
torch.__version__
torch.__file__
import tensorflow as tf
import tensroflow as tf
import tensorflow as tf
tf.__file__
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.test.is_built_with_cuda()
import tensorflow as tf
tf.test.is_built_with_cuda()
tf.test.is_built_with_gpu_support()
tf.test.is_built_with_xla()
tf.test.gpu_device_name()
import os
os.getcwd()
os.chdir('..')
os.getcwd()
from coroaverager2 import *
coro_avg = averager2()
next(coro_avg)
coro_avg.send(10)
coro_avg.send(30)
coro_avg.send(6.5)
coro_avg.send(STOP)
from contravariant import *
compost_can: TrashCan[Compostable] = TrashCan()
compost_can
trashcan_can: TrashCan[Refuse] = TrashCan()
deploy(trash_can)
deploy(compost_can)
pip install --upgrade pip
import tensorflow as tf
impor keras
import keras
import tensorflow as tf
tf.__version__
import keras
tf.__version__
tf.__file__
import keras
import tensorflow as tf
tf.__version__
import keras
keras.__version__
from keras.utils import pad_sequences
pad_sequences
import pydantic
pydantic.__version__
import pydantic
pydantic.__version__
import pydantic
pydantic.__version__
import tensorflow as tf
tf.__version__
import mypy
mypy.__version__
import black
black.__version__
def inc(x):
x += 1
def inc(x):
	x += 1
import dis
dis.dis(inc)
1 == 1.0
hash(1)
hash(1.0)
hash(-1.0)
hash(-1)
hash(-2)
hash(-2.0)
workdays = {'Mon', 'Tue', 'Wed', 'Thu', 'Fri'}
workdays
hash('Mon')
hash('mon')
hash('Mon')%8
s = {1.0, 2.0, 3.0}
s
s.add(1)
s
s.add(4)
s
s.add(4.0)
s
hash('Mon')
id('Mon')
import tensorflow as tf
import pandas as pd
import tensorflow as tf
import tensorflow
import tensorflow as tf
import pandas as pd
import tensorflow as tf
import dask
from pymongo import MongoClient
client = MongoClient('mongodb://localhost:27017/')
db = client['eos']
coll = db.get_collection('coll_episode_road')
count = coll.count_documents({})
counnt
count
cursor = coll.find({})
for doc in cursor:
	print(doc['observation'])
for doc in cursor:
	print(len(doc['observation']))
cursor = coll.find({})
for doc in cursor:
	print(len(doc['observation']))
import tensorflow as tf
def my_function(x):
    return x * 2
@tf.function
def decorated_function(x):
    input_signature = tf.TensorSpec(shape=[None], dtype=tf.float32)
    return my_function(x)
decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
class TestDecoratedFunction(unittest.TestCase):
    def test_change_input_signature(self):
        # Change the input_signature to have a shape of [2]
        decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
        # Call the function with a shape of [2]
        result = decorated_function([1, 2])
        # The result should be a tensor with a shape of [2]
        self.assertEqual(result.shape, [2])
if __name__ == "__main__":
    unittest.main()
import unittest
class TestDecoratedFunction(unittest.TestCase):
    def test_change_input_signature(self):
        # Change the input_signature to have a shape of [2]
        decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
        # Call the function with a shape of [2]
        result = decorated_function([1, 2])
        # The result should be a tensor with a shape of [2]
        self.assertEqual(result.shape, [2])
class TestDecoratedFunction(unittest.TestCase):
    def test_change_input_signature(self):
        # Change the input_signature to have a shape of [2]
        decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
        # Call the function with a shape of [2]
        result = decorated_function([1, 2])
        # The result should be a tensor with a shape of [2]
        self.assertEqual(result.shape, [2])
class TestDecoratedFunction(unittest.TestCase):
    def test_change_input_signature(self):
        decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
        result = decorated_function([1, 2])
        self.assertEqual(result.shape, [2])
unittest.main()
import tensorflow as tf
def my_function(x):
    return x * 2
@tf.function
def decorated_function(x):
    input_signature = tf.TensorSpec(shape=[None], dtype=tf.float32)
    return my_function(x)
decorated_function.input_signature = tf.TensorSpec(shape=[2], dtype=tf.float32)
decorated_function.input_signature
print(decorated_function.input_signature)
import numpy as np
x = np.arange(15.0)
x
np.array_split(x,2)
x = np.arange(16.0)
x
np.array_split(x,2)
8%3
8//3
np.array_split(x,4)
np.array_split(x,5)
np.split(x,3)
l = 16
s = 3
n = l//s
n
r = l%s
r
ind = arange(n)*s
ind = range(n)*s
ind = np.arange(n)
ind
ind = np.arange(n)*s
indx
ind
l
nind = ind.append(l)
nind = list(ind).append(l)
nind
ind
list(ind)
nind = list(ind)+[l]
nind
x
xs = np.split(x,nind)
xs
xs1 = np.split(x,ind)
xs1
ind = np.arange(l//s)*s
ind
xs = np.split(x,ind)
xs
xs = np.split(x,np.arange(l//s)*s)
xs
ind = np.arange(l//s)*s
ind
ind = np.arange(l//s)[0:]*s
ind
np.arange(l//s)
np.arange(l//s)[1:]
ind = np.arange(l//s)[1:]*s
xs = np.split(x,np.arange(l//s)[1:]*s)
xs
ind
np.array_split(x,ind)
ind = np.arange(l//s)[1:]*s
inx
ind
s
s =16
ind = np.arange(l//s)[1:]*s
ind
len(ind)
ind == []
s =16
l
ind = np.arange(l//s)[1:]*s
ind
ind = np.arange(l//s)*s
ind
s =15
ind = np.arange(l//s)*s
ind
np.arange(16//15)
16//15
np.arange(1)
np.arange(2)
ind_split = np.array([l])
ind_split
np.array_split(x, ind_split)
np.array_split(x, [])
np.array_split(x, np.array([]))
np.arange(16//15)
np.arange(16//5)
np.arange(16//5)[1:]
np.arange(16//5)[1:]*5
np.arange(16//5)+1
(np.arange(16//5)+1)*5
ind = (np.arange(l//s)+1)*s
s
l
ind
s = 5
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 15
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 12
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 16
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 17
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 17
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
s = 16
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
for i, batch_t in enuemrate(np.array_split(x,ind):
for i, batch_t in enuemrate(np.array_split(x,ind)):
	print(i, batch_t)
for i, batch_t in enumerate(np.array_split(x,ind)):
	print(i, batch_t)
ind
any(False, False, True)
any((False, False, True))
any((False, False, False))
s = 3
ind = (np.arange(l//s)+1)*s
ind
np.array_split(x, ind)
import pydantic
pydantic.__version__
import os
os.__file__
import mypy
mypy.__file__
mypy.__version__
import dask
import pydantic
from pydantic import mypy
import pydantic.mypy
import mypy
mypy.__version__
mypy.__file__
from git import Repo
impor os
import os
os.getcwd()
repo = Repo(.)
repo = Repo('.')
from pathlib import Path
repo = Repo(Path('.'))
repo = Repo(os.getcwd())
from eos import proj_root
import faiss
import langchain
langchain.__version__
import langchain_experimental
import cv2
cv2.__file__
cv2.__version__
from pathlib import Path
import os
p = os.getcwd()
p
type(p)
p = Path(os.getcwd())
p
p.cwd()
p1 = p / 'static'
p1
p1.getcwd()
p1.cwd()
p1
p1.parts
p1.cwd()
p1
saved_filename = p1.cwd() / p1.parts[-1] / '.gif'
saved_filename
saved_filename = p1.cwd() / (p1.parts[-1]+'.gif')
saved_filename
p1
p1 / '*.png'
glob.glob(p1 / '*.png')
import glob
glob.glob(p1 / '*.png')
glob.glob(str(p1 / '*.png'))
import imageio
imageio.help("gif)
imageio.help("gif")
import os
os.getcwd()
from sentence import Sentence
s = Sentence('"The time has com, " the Walrus said,')
print(s)
s
for word in s:
	print(word)
list(s)
class Spam:
	def __getitem__(self, i):
		print('->', i)
		raise IndexError()
spam_can =Spam()
iter(spam_can)
list(spam_can)
next(spam_can)
spam_can =Spam()
next(spam_can)
iter(spam_can)
list(spam_can)
from collections import abc
isinstance(spam_can, abc.Iterable)
iter(spam_can)
x = 1
iter(x)
def d6():
	return randint(1,6)
d6_iter = iter(d6,1)
d6_iter
for roll in d6_iter:
	print(roll)
from random import randint
for roll in d6_iter:
	print(roll)
s3 = Sentence('Life of Brian')
it = iter(s3)
it
next(it)
list(it)
next(it)
from sentence_iter import Sentence
s = Sentence('"The time has com, " the Walrus said,')
s
type(s)
iter(s)
next(iter)
next(s)
it = iter(s)
next(it)
it.__next__()
from sentence_iter_wrong import Sentence
s = Sentence('"The time has com, " the Walrus said,')
it = iter(s)
list(it)
next(it)
s
type(s0
type(s)
iter(s)
it = iter(s)
next(it)
s
s.index = 0
it = iter(s)
next(s)
list(it)
next(it)
s
type(s0
type(s)
it = iter(s)
it
type(it)
for i in iter:
	print(i)
for i in it:
	print(it)
it = iter(s)
for i in it:
	print(it)
next(it)
it = iter(s)
next(it)
s.index = 0
it = iter(s)
for i in it:
	print(it)
s.index = 0
it = iter(s)
for i in it:
	print(i)
for i in s:
	printIi)
for i in s:
	print(i)
s.index = 0
for i in s:
	print(i)
next(s0
next(s)
s.index=0
next(s)
def gen_1():
	yield 1
gen_1
gen_1()
for i in gen_1():
	print(i)
for i in gen_123():
	yield 1
    print('first')
for i in gen_123():
	yield 1
    print('first')
def gen_123():
	yield 1
	print('first')
	yield 2
	print('second')
	yield 3
	print('third')
for i in gen_123():
	print(i)
g = gen_123()
next(g)
from coroaverager import averager
coro_avg = averager()
next(coro_avg)
coro_avg.send(10)
coro_avg.send(20)
coro_avg.send(30)
coro_avg.send(5)
coro_avg.close()
coro_avg
coro_avg.send(5)
coro_avg.close()
from coroaverager2 import averager2, STOP
coro_avg = averager2()
next(coro_avg)
coro_avg.send(10)
coro_avg.send(30)
coro_avg.send(6.5)
coro_avg.close()
coro_avg = averager2()
next(coro_avg)
coro_avg.send(10)
coro_avg.send(30)
coro_avg.send(6.5)
try: 
	coro.avg.send(STOP)
except StopIteration as exc:
	result = exc.value
try: 
	coro_avg.send(STOP)
except StopIteration as exc:
	result = exc.value
result
from mirror import LookingGlass
manager = LookingGlass()
manager
monster = manager.__enter__()
monster
monster == 'JABBERWOCKY'
manager
1/0
manager.__exit(None,None,None)
manager.__exit__(None,None,None)
monster
manager.__exit__(ZeroDivisionError,None,None)
with LookingGlass() as what:
	print('Alice, Kitty and Snowdrop')
	print(what)
	x=5/0
with LookingGlass() as what:
	print('Alice, Kitty and Snowdrop')
	print(what)
	x=sqrt(-1.0)
with LookingGlass() as what:
	print('Alice, Kitty and Snowdrop')
	print(what)
    x[0]
with LookingGlass() as what:
	print(what)
	print(x)
l = list()
l
l1 = []
id(l)
id(l1)
l2 = []
id(l2)
l
id(l)
id(list())
l1
id(l1)
l1.append(2)
l1
id(l1)
l2
id(l2)
l1 = []
id(l1)
l2 = []
id(l2)
import os
import pandas as pd
os.getcwd()
proj_root = Path(os.getcwd()).resolve().parent
from pathlib import Path
proj_root = Path(os.getcwd()).resolve().parent
proj_root
proj_root = proj_root.parent
proj_root
data_dir = proj_root.join('data')
data_dir = proj_root.joinpath('data')
data_dir
table = pd.read_csv(proj_root / "eos/data_io/config" / "vb7_init_table.csv")
table = pd.read_csv(proj_root / "eos/eos/data_io/config" / "vb7_init_table.csv")
table
table = pd.read_csv(proj_root / "eos/eos/data_io/config" / "vb7_init_table.csv", index_col=0)
table
table_live = table.copy()
table_live
import socket
socket.gethostname()
import socket
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.connect((("www.python.org", 80))
s.connect(("www.python.org", 80))
import rocketmq as rmq
rmq.__file__
import tensorflow as tf
tf.test.gpu_device_name()
tf.config.list_physical_devices(
tf.config.list_physical_devices()
import tensorflow as tf
tf.config.list_physical_devices()
tf.test.gpu_device_name()
import tensorflow as tf
tf.test.gpu_device_name()
import tensorflow as tf
tf.__version__
import tensorflow as tf
tf.config.list_physical_devices()
import tensorflow as tf
tf.config.list_physical_devices(
tf.config.list_physical_devices()
import tensorflow as tf
tf.__file__
tf.config.list_physical_devices(
tf.config.list_physical_devices()
import tensorflow as tf
tf.__file__
tf.__version__
import tensorflow as tf
tf.__version__
tf.__file__
import tensorflow as tf
tf.__file__
tf.__version__
tf.config.list_physical_devices(
tf.config.list_physical_devices()
tf.test.is_gpu_available()
tf.test.is_built_with_cuda()
import tensorflow as tf
tf.__file__
tf.__version__
import pydantic
pydantic.__version__
import tensorflow as tf
tf.__version__
import pyarrow as pa
pa.__version__
pa.__file__
import tensorflow as tf
tf.__version__
tf.__file__
import pydantic
pydantic.__version__
import pyarrow as pa
pa.__version__
import dask
dask.__version__
import fastavro
fastavro.__version__
import yaml
import os
os.getcwd()
data = yaml.load(open('./tflite_convert.ipynb'))
f = load('./tflite_convert.ipynb')
f = open('./tflite_convert.ipynb')
data = yaml.load(f)
from yaml import CLoader as Loader, CDumper as Dumper
data = yaml.load(f,Loader=Loader)
data
import json
json.dump(data,'tflite_convert_stripped.jpynb')
s = json.dumps(data)
with open("./tflite_convert_stripped.ipynb", "w") as f:
	f.write(s)
f = open('./tflite_convert_restore.ipynb')
data = yaml.load(f)
data = yaml.load(f,Loader=Loader)
with open("./tflite_convert_restore_stripped.ipynb", "w") as f:
s
s = json.dumps(data)
with open("./tflite_convert_restore_stripped.ipynb", "w") as f:
	f.write(s)
data = yaml.load(f,Loader=Loader)
s = json.dumps(data)
with open("./eos_timeseries_dataframe_stripped.ipynb", "w") as f:
	f.write(s)
import os
os.__file__
import eos
eos.__version__
eos.__file__
import nbdev
nbdev.__file__
nbdev.__version__
import nbdev
nbdev.__version__
import dataset
from huggingface import dataset
from datasets import load_dataset
import xeus-cling
import clas
import clad
import tensorflow as tf
tf.__version__
tf.test.is_gpu_available()
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.test.is_built_with_cuda()
tf.test.is_built_with_gpu_support()
import tensorflow as tf
tf.test.is_gpu_available()
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.config.list_physical_devices('GPU')
tf.test.is_built_with_cuda()
tf.test.is_built_with_gpu_support()
import tensorflow as tf
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.config.list_physical_devices('GPU')
import tensorflow as tf
tf.test.is_built_with_cuda()
cd ..
import tensorflow as tf
tf.test.is_built_with_cuda()
import keras
keras.__version__
tf.__version__
import a2lparser
a2lparser.__file__
a2lparser.__version__
import a2lparser
a2lparser.__file__
a2lparser.__version__
from a2lparser import __version__
from a2lparser.a2l.parser import Parser
import a2lparser
from a2lparser.a2l.parser import Parser
Parser
import a2lparser
a2lparser.__file__
import os
os.getcwd()
from pya2l import DB
db = DB()
session = db.import_a2l("../ASAP2_Demo_V161.a2l")
from pya2l import DB
db = DB()
session = db.import_a2l("../ASAP2_Demo_V161.a2l")
import os
os.getcwd
os.getcwd()
session = db.import_a2l("examples/ASAP2_Demo_V161.a2l")
session = db.import_a2l("ASAP2_Demo_V161.a2l")
db = DB()
os.getcwd()
session = db.import_a2l("examples/ASAP2_Demo_V161.a2l")
import pya2l.model as model
model.__dict__
model.Measurement
model.Measurement.__dict__
measurements = session.query(model.Measurement).order_by(model.Measurement.name).all()
for m in measurements:
print(f"{m.name:48} {m.datatype:12} 0x{m.ecu_address.address:08x}")
for m in measurements:
	print(f"{m.name:48} {m.datatype:12} 0x{m.ecu_address.address:08x}")
session = db.import_a2l("examples/VBU.a2l")
session2 = db.import_a2l("examples/VBU.a2l")
import os
from pya2l import DB
os.getcwd()
db = DB()
session = db.import_a2l("examples/VBU.a2l")
from pya2l import DB
import os
os.getcwd()
db = DB()
session = db.import_a2l("examples/ASAP2_DEMO_V161.a2l")
session = db.import_a2l("examples/ASAP2_Demo_V161.a2l")
import os
from pya2l import DB
db = DB()
session = db.import_a2l("examples/ASAP2_Demo_V161.a2l")
import os
from pya2l import DB
db = DB()
session = db.import_a2l("examples/ASAP2_Demo_V161.a2l")
measurements = session.query(model.Measurement).order_by(model.Measurement.name).all()
import pya2l.model as model
measurements = session.query(model.Measurement).order_by(model.Measurement.name).all()
for m in measurements:
	print(f"{m.name:48} {m.datatype:12} 0x{m.ecu_address.address:08x}")
import os
from pya2l import DB
db = DB()
seesion
session
session = db.import_a2l("examples/VBU.a2l")
session = db.open_existing("VBU")
session = db.open_existing("VBU")
from pya2l import DB
db = DB()
session = db.import_a2l("examples/VBU.a2l")
from pya2l import DB
db = DB()
session = db.import_a2l("examples/VBU_1.6.1.a2l")
session = db.import_a2l("examples/VBU_1_61.a2l")
from pya2l import DB
db = DB()
session = db.import_a2l("examples/VBU_1_61.a2l")
import schedule_v1
import os
os.getcwd()
from schedule_v1 import Record, load, JSON_PATH
import nbdev
from nbdev.showdo import *
from nbdev.showdoc import *
from nbdev import *
nbdev.__dict__
import nbdev
nbdev.__dict__
nbdev.__version__
nbdev.__file__
import ijson.backends.yajl2_c as ijson
import nbdev
nbdev.__file__
import tensorflow as tf
tf.__file__
from schedule_dataclass_v6 import *
record = load(JSON_PATH)
speaker = records['speaker.3471']
speaker = record['speaker.3471']
speaker.name, speaker.twitter
speaker
from schedule_dataclass_v6 import *
event = Record.fetch('event.33950')
event
from schedule_v5 import *
event = Record.fetch(event.33950')
event = Record.fetch('event.33950')
event.venue
event.venue.name
from schedule_composition_v7 import *
event = Record.fetch('event.33950')
event.venue.name
from schedule_composition_v7 import *
event = Record.fetch('event.33950')
event.venue.name
from schedule_composition_v7 import *
l = ['a', 'b', 'c']
l.remove('a')
l
l = ['a', 'b', 'c', 'a', 'b']
l
l.remove('a')
l
l = ['a', 'b', 'c', 'a', 'b']
l.remove('b')
l
a = []
a is False
a is True
a.empty()
a
not a
a == False
bool(a)
a
d
l
l = ['a', 'b', 'c', 'a', 'b']
m = list(l)
m
m.remove('a')
m.pop()
m
l
a = 'ab'
a.title()
a
t = (2, 4)
t
type(t)
t[0]
import cantools
import can
can_bus = can.interface.Bus('vcan0', bustype='socketcan')
message = can_bus.recv()
message
db = cantools.database.load_file('../tests/files/dbc/motohawk.dbc')
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
db.decode_message(message.arbitration_id, message.data)
message = can_bus.recv()
import cantools
import can
from cantools.database import Message
from can.interface import Bus
db = cantools.database.load_file('./motohawk_new.dbc')
db.messages
example_message = db.get_message_by_name(''ExampleMessage')
example_message = db.get_message_by_name('ExampleMessage')
example_message.frame_id
example_message.signal_groups
example_message.signal_tree
bus = Bus(bustype='socketcan', channel='vcan0', bitrate=25000)
bus.fileno()
msg = bus.recv()
datetime.fromtimestamp(message_proxy['timestamp']),db.d(message_proxy['arbitration_id'],message_proxy['data'])
from datetime import datetime
datetime.fromtimestamp(message_proxy['timestamp']),db.d(message_proxy['arbitration_id'],message_proxy['data'])
datetime.fromtimestamp(msg['timestamp']),db.d(msg['arbitration_id'],msg['data'])
msg
datetime.fromtimestamp(msg['timestamp']),db.decode(msg['arbitration_id'],msg['data'])
msg.timestamp
msg.arbitration_id
msg.data
datetime.fromtimestamp(msg.timestamp),db.decode(msg.arbitration_id,msg.data)
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg.data
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
bus
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg
bus.send(msg)
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
bus.fileno()
msg = bus.recv()
datetime.fromtimestamp(msg.timestamp),db.decode_message(msg.arbitration_id,msg.data)
msg = bus.recv()
import numpy
numpy.__file__
string='hello, world!'
encoded = string.encode('utf-8')
encoded
type(encoded)
import cantools
import can
can.__version__
import can
can.__version__
import tensorflow as tf
tf.__file__
tf.__version__
import tensorflow as tf
tf.__version__
tf.__file__
import tensorflow as tf
tf.__file__
tf.__version__
s = r'/project[0]/module[0,3,5]'
s
type(s)
bs = bytes(s)
bs = bytearray(s, 'utf-8')
bs
type(bs)
bs[0]
bs[1]
string(bs[1])
str(bs[1])
bs = bytes(s, 'utf-8')
bs
default=r"TQD_trqTrqSetNormal_MAP_v, " 
				r"VBU_L045A_CWP_05_09T_AImode_CM_single, "
default=r"TQD_trqTrqSetNormal_MAP_v, "
default=r"TQD_trqTrqSetNormal_MAP_v, " \
				r"VBU_L045A_CWP_05_09T_AImode_CM_single, "
defautl
default
default=r"TQD_trqTrqSetNormal_MAP_v, "\
				r"VBU_L045A_CWP_05_09T_AImode_CM_single, "\ 
				r"Lookup2D_FLOAT32_IEEE, "\
				r"Lookup2D_X_FLOAT32_IEEE, "\ 
				r"Scalar_FLOAT32_IEEE, "\
				r"TQD_vVehSpd, "\
				r"TQD_vSgndSpd_MAP_y, "\
				r"TQD_pctAccPedPosFlt, "\
import cantools
cantools.__file__
import tensorflow as tf
from scapy.all import *
pkt = IP()
pkt.canvas_dump()
sniff(filter="icmp and host 66.35.250.151", count=2)
import fastapi
fastapi.__version__
fastapi.__file__
import tensorflow as tf
tf.__version__
import keras
keras.__version__
import tensorflow as tf
tf.__version__
tf.__file__
tf.config.list_physical_devices('GPU')
tf.debugging.set_log_device_placement(True)
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
c = tf.matmul(a, b)
print(c)
with tf.device('/CPU:0'):
  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
c = tf.matmul(a, b)
print(c)
gpus = tf.config.list_physical_devices('GPU')
gpus
i = 631
i.hex()
hex(i)
hex(631)
hex(630)
int(0x7ff)
int('0x7ff')
int('0x7ff', 16)
a = '7000aa2a'
int(a, base=16)
na = int(a, base=16)+4
na
hex(na)
c = []
c.append([1,2,3])
c1.append(**[1,2,3])
c1=[]
c1.append(**[1,2,3])
c1.append(*[1,2,3])
c1
c1 = c1 + [1,2,3]
c1
c1 = c1 + [1,2,3]
c1
i = 10
i = 0x01
i
i = 0x0f
i
3207.56+10000+10000+20000+30000+12617.25+17995.75+11998+8610.76+12000+15000+10000
in = 3207.56+10000+10000+20000+30000+12617.25+17995.75+11998+8610.76+12000+15000+10000
inward = 3207.56+10000+10000+20000+30000+12617.25+17995.75+11998+8610.76+12000+15000+10000
inward
status = 182420.66
profit = status - inward
profit
print(f"capital:{status}-investment:{inward} = profit:{profit}"
)
print(f"capital:{status}-investment:{inward} = profit:{profit}")
print(f"capital({status})-investment({inward}) = profit({profit})")
print(f"capital({status})-investment({inward}) = profit({profit:.2f})")
profit/inward
t = "SOCKET"
t
t.lower()
import git
git.__file__
import virtualmachine
virtualmachine.name()
virtualmachine.id()
virtualmachine.name() == None
virtualmachine.name() == ''
virtualmachine.version()
?virtualmachine.id
?virtualmachine.id?
import platform
platform.system()
import platform
platform.system()
import random
random.seed(73)
data = [random.expovariate(1/3) for _ in range(1000)]
data
dim(data)
data.shape
data
len(data)
import textual
